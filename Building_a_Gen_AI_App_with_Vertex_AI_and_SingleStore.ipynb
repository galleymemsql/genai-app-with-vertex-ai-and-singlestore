{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# prompt: Create a function in python to greab the last 100 tweets from twitter on crypto\n",
        "\n",
        "import tweepy\n",
        "\n",
        "def get_last_100_tweets_on_crypto():\n",
        "  # Create a Twitter API client\n",
        "  api = tweepy.Client(bearer_token=\"YOUR_BEARER_TOKEN\")\n",
        "\n",
        "  # Get the last 100 tweets that mention \"crypto\"\n",
        "  tweets = api.search_recent_tweets(query=\"crypto\", tweet_fields=[\"text\"])\n",
        "\n",
        "  # Return the tweets\n",
        "  return tweets\n"
      ],
      "metadata": {
        "id": "OHnViKM3PWu9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Create a function in python to greab the last 100 tweets from twitter on crypto\n"
      ],
      "metadata": {
        "id": "-KmlOoUWD_KC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "34191f94-ca33-448c-ce2f-b709f58e1424"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-38bd77be6deb>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Create a function in python to greab the last 100 tweets from twitter on crypto\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a Generative AI Application with Vertex AI and SingleStore\n",
        "\n",
        "Welcome to this comprehensive guide on building a state-of-the-art General AI application using Google Cloud's Vertex AI and SingleStoreDB. This guide aims to provide a seamless experience, offering step-by-step instructions, code explanations, and best practices.\n",
        "\n",
        "## Overview\n",
        "Vertex AI, a product by Google Cloud, offers an integrated suite of machine learning tools that allows developers to build, deploy, and scale AI models faster than ever. On the other hand, SingleStoreDB offers a fast, scalable, and SQL-compliant relational database system. By combining the power of Vertex AI's machine learning capabilities with the efficient storage and retrieval mechanisms of SingleStoreDB, we can create robust AI applications that respond to user queries in real-time.\n",
        "\n",
        "## What You'll Learn\n",
        "- Setting up your environment with the necessary packages and credentials.\n",
        "- Fetching and processing data to be used in our AI models.\n",
        "- Storing and managing data efficiently using SingleStoreDB.\n",
        "- Leveraging the power of Vertex AI for real-time data processing and insights.\n",
        "- Building a retrieval-based QA system to answer user queries.\n",
        "\n",
        "## Prerequisites\n",
        "- Basic knowledge of Python programming.\n",
        "- Familiarity with Google Cloud services and SQL databases.\n",
        "- An active Google Cloud account.\n",
        "- A SingleStoreDB hosted or self-managed instance.\n",
        "\n",
        "Let's dive in and start building!\n",
        "\n"
      ],
      "metadata": {
        "id": "f9mswTdkXAbM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Setting up the environment**:\n",
        "Install the required libraries.\n",
        "\n",
        "**IMPORTANT**\n",
        "Restart the runtime as prompted"
      ],
      "metadata": {
        "id": "XgWYZiP0WEqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gcloud\n",
        "!pip install langchain\n",
        "!pip install singlestoredb\n",
        "!pip install shapely==1.8.5\n",
        "!pip install pypdf\n",
        "!pip install google-cloud-aiplatform\n"
      ],
      "metadata": {
        "id": "FcV4SNejTueB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Authentication**:\n",
        "The next step involves authenticating our session with Google Cloud. By running the following cell, you'll be prompted to log in using your Google Cloud credentials. Follow the instructions to complete the login process."
      ],
      "metadata": {
        "id": "a95wJuh3WIoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth application-default login"
      ],
      "metadata": {
        "id": "OyAnbOrET4ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternative method to authenticate"
      ],
      "metadata": {
        "id": "YSvBXL-9FBcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import auth as google_auth\n",
        "#google_auth.authenticate_user()\n",
        "\n",
        "#from google.cloud import aiplatform\n",
        "#aiplatform.init(project=\"isv-coe-denisj-00\")"
      ],
      "metadata": {
        "id": "pqERdrjGtBEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting the Quota Project**: After authentication, we need to set our quota project. Replace my-project-1516239077425 with your project ID if different, then run the cell to set the quota project for this session."
      ],
      "metadata": {
        "id": "0CIXY7rnWSvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth application-default set-quota-project cpe-ai-build"
      ],
      "metadata": {
        "id": "m8-IyCVrVMVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config set project cpe-ai-build"
      ],
      "metadata": {
        "id": "UUJKNU5pVayy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Import modules, initialize, load/chunk data**"
      ],
      "metadata": {
        "id": "Cn-GLeNvF00F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Necessary Modules**: With the initial setup complete, let's import the essential classes and modules we'll use throughout this project. The following cell imports the required classes from langchain and SingleStoreDB."
      ],
      "metadata": {
        "id": "bhjfVEtLWbY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import VertexAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.vectorstores import SingleStoreDB"
      ],
      "metadata": {
        "id": "mOrNmx-UYXNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initializing Vertex AI**: To interact with Google Cloud's Vertex AI services, we first need to instantiate the VertexAI class. Running the cell below will create this instance and store it in the variable llm.\n",
        "\n",
        "By default this will use text-bison model. So specify a different model use the following example:\n",
        "`llm = VertexAI(model_name=\"code-bison\")`"
      ],
      "metadata": {
        "id": "RauqldUWWnkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = VertexAI(model_name=\"text-bison\", max_output_tokens=2048)"
      ],
      "metadata": {
        "id": "UlheSh1KY4zW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Data from the Web**: Our application requires data to process and generate insights. In this step, we'll fetch content from a URL using the WebBaseLoader class. The loaded data will be stored in the data variable. You can replace the URL with any other source if needed.\n"
      ],
      "metadata": {
        "id": "CmyJjgNeWu6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = WebBaseLoader(\"https://cloud.google.com/vertex-ai/docs/generative-ai/learn/generative-ai-studio\")\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "7ZD6Dk16sVzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Data from the PDF**: In this step, we'll fetch content from a PDF file stored locally on the system using the PyPDFLoader class. The loaded data will be stored in the data variable."
      ],
      "metadata": {
        "id": "rGkruc9Xj9cM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/home/NBA-CBA-6-28-23.pdf\" )\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "x4-qk52Kj_zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages[1]"
      ],
      "metadata": {
        "id": "MwfbluhdXyLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Splitting the Data**: To process the data more efficiently, we'll split the loaded content into smaller chunks. The RecursiveCharacterTextSplitter class helps in achieving this by dividing the data based on specified character limits."
      ],
      "metadata": {
        "id": "i_Yvk8JeWwxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 4096, chunk_overlap = 410)\n",
        "all_splits = text_splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "uwDl1n51s4ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Setting Up SingleStoreDB with Vertex AI Embeddings**:\n",
        "For efficient storage and retrieval of our data, we use SingleStoreDB in conjunction with Vertex AI embeddings. The following cell sets up the necessary environment variables and initializes the SingleStoreDB instance with Vertex AI embeddings. Ensure you have the correct SingleStoreDB URL and credentials set.\n"
      ],
      "metadata": {
        "id": "eKJtR8piWzDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.prompts import PromptTemplate\n",
        "import os\n",
        "\n",
        "os.environ[\"SINGLESTOREDB_URL\"] = \"admin:{your admin password}.{your singlestore host}:3306/{your database name}\"\n",
        "\n",
        "vectorstore = SingleStoreDB.from_documents(documents=all_splits, embedding=VertexAIEmbeddings())\n",
        "#vectorstore = SingleStoreDB(embedding=VertexAIEmbeddings())"
      ],
      "metadata": {
        "id": "Y2rg9XHztDfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever=vectorstore.as_retriever(search_type=\"similarity\")\n",
        "\n",
        "template = \"\"\"Use the following pieces of context about the NBA CBA to answer the question at the end.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "Be verbose and explain your answer in simple english.\n",
        "Always say \"thanks for asking!\" at the end of the answer.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "LZIALuFnu1b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Setting Up and Testing the QA Chain**:\n",
        "Once our data is processed and stored, we can use it to answer queries. The following cell initializes the RetrievalQA chain using the previously set up llm and vectorstore. After initializing, it tests the setup with a sample question about Vertex AI.\n",
        "\n"
      ],
      "metadata": {
        "id": "fEm4FJBYW3B4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(llm,retriever=retriever,return_source_documents=1, chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})\n",
        "qa_chain({\"query\": \"How many games does an NBA player have to play in order to be eligible to win MVP?\"})"
      ],
      "metadata": {
        "id": "bJaFpHBBtrCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain({\"query\": \"What is the best database company?\"})"
      ],
      "metadata": {
        "id": "je7Nvs2oLpBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain({\"query\": \"What is the NBA policy on meal expenses this year?\"})"
      ],
      "metadata": {
        "id": "m8kOLbrgIhCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain({\"query\": \"Do NBA players get 401k matching, provide details?\"})"
      ],
      "metadata": {
        "id": "bPeHj86spEBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain({\"query\": \"Explain details about how the In-season tournament will be played\"})"
      ],
      "metadata": {
        "id": "SDcjPmiPItQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain({\"query\": \"How much is NBA player pension?\"})"
      ],
      "metadata": {
        "id": "1MaIxh4b8H1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain({\"query\":\"What does the runner up of the in-Season Tournament get\"})"
      ],
      "metadata": {
        "id": "n7GrtsyeHVOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain({\"query\":\"What incentive do teams have for participating in the in-Season Tournament?\"})"
      ],
      "metadata": {
        "id": "uApGwgMdIB37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain({\"query\": \"What is the maxium increase in salary for veteran extensions\"})"
      ],
      "metadata": {
        "id": "0jBX9UZdIooX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain({\"query\": \"What is the maxium allowed increase in league salary cap?\"})"
      ],
      "metadata": {
        "id": "LCS3irSHK5gx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}